# Gated Recurrent Network (GRU) breakdown
This is a type of Recurrent Neural Network (RNN) that is similar to the LSTM but GRU uses less memory and is faster. You should use this model over LSTM when you have shorter sequences.

- Why to use?:
  - Addresses the Vanishing Gradient problem
  - Uses an update and reset gate to learn

- GRU.ipynb is the notebook associated with the [GRU YouTube Video](https://youtu.be/rdz0UqQz5Sw)
