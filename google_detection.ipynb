{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pwq15TykKHhV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to scrape Google search results and extract summaries\n",
        "def scrape_google_search(query, num_results=10):\n",
        "    search_url = f\"https://www.google.com/search?q={query}&num={num_results}\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        search_results = soup.find_all(\"div\", class_=\"tF2Cxc\")\n",
        "        summaries = [result.find(\"div\", class_=\"IsZvec\").text for result in search_results]\n",
        "        return summaries\n",
        "    else:\n",
        "        print(f\"Failed to retrieve Google search results for '{query}'\")\n",
        "        return []\n",
        "\n",
        "# Function to check for plagiarism between a user query and search result summaries\n",
        "def plagiarism_checker(user_query, search_summaries):\n",
        "    user_query = user_query.lower()  # Convert to lowercase for comparison\n",
        "\n",
        "    for idx, summary in enumerate(search_summaries):\n",
        "        summary = summary.lower()  # Convert to lowercase for comparison\n",
        "\n",
        "        # Create TF-IDF vectorizers for the user query and summary\n",
        "        tfidf_vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = tfidf_vectorizer.fit_transform([user_query, summary])\n",
        "\n",
        "        # Calculate cosine similarity between the TF-IDF vectors\n",
        "        similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "\n",
        "        # Set a similarity threshold to determine plagiarism\n",
        "        threshold = 0.8\n",
        "\n",
        "        if similarity > threshold:\n",
        "            print(f\"Search result {idx + 1} is potentially plagiarized:\")\n",
        "            print(summary)\n",
        "            print(f\"Similarity score: {similarity}\")\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "    print(\"Plagiarism detection complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user_query = \"What is Java?\"  # Replace with the user's query\n",
        "    search_summaries = scrape_google_search(user_query)\n",
        "\n",
        "    if search_summaries:\n",
        "        plagiarism_checker(user_query, search_summaries)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googlesearch import search\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to perform a Google search and extract search result snippets\n",
        "def google_search(query, num_results=10):\n",
        "    search_results = list(search(query, num=num_results, stop=num_results))\n",
        "    snippets = []\n",
        "\n",
        "    for result in search_results:\n",
        "        try:\n",
        "            response = requests.get(result)\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            snippet = soup.get_text()\n",
        "            snippets.append(snippet)\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching content from {result}: {e}\")\n",
        "\n",
        "    return snippets\n",
        "\n",
        "# Function to check for plagiarism using TF-IDF and cosine similarity\n",
        "def plagiarism_checker(text1, text2):\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform([text1, text2])\n",
        "    similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "\n",
        "    # Set a similarity threshold to determine plagiarism\n",
        "    threshold = 0.8\n",
        "\n",
        "    if similarity > threshold:\n",
        "        return \"Plagiarized\"\n",
        "    else:\n",
        "        return \"Not Plagiarized\"\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    query = \"What is Java?\"\n",
        "    search_results = google_search(query)\n",
        "\n",
        "    # Check for plagiarism against the first search result\n",
        "    if len(search_results) >= 2:\n",
        "        query_result = search_results[0]\n",
        "        for i, snippet in enumerate(search_results[1:], start=2):\n",
        "            result = plagiarism_checker(query_result, snippet)\n",
        "            print(f\"Search result {i}: {result}\")\n",
        "\n",
        "        print(\"\\nPlagiarism check against the first search result completed.\")\n",
        "    else:\n",
        "        print(\"Insufficient search results to perform plagiarism check.\")\n"
      ],
      "metadata": {
        "id": "OqSTKsNyKvRM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}